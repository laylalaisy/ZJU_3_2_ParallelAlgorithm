 # Lecture 1

## Parallel Algorithm

Important factors:

1. Number of processors

2. Time

Operation is the product of time and number of processors.

## Example 1

Summing n numbers

1. 大于等于n/2个processor Time：log2（n）    
Divide and conquer with n/2 processors. Then we can always do each step in parallel, so the time is the number of steps, log(n).
就是两两配对，类似一个倒着的binary tree，因此processor：n/2个，Time：log2（n）

    ```
    for (i = 0, i < log(n), ++i) {
        for P % 2^(i+1) == 0 do in parallel {
            // P starts with 0.
            A[P] = A[P] + A[P+2^i];
        }
    }
    ```

2. n/log(n)个processor  O(log(n))    
先每个组log(n)个数字，分成n/log(n)个组，此时每个组1个processor，顺序相加O(log(n))；然后每组的结果一共是n/log(n)用n/log(n)个processor通过上述方法相加，为O(log(n/log(n));    
Use less processors. Group by log(n) numbers, and use n/log(n) processors. Then we have one processor for each group, and we can sum each group sequentially in log(n) time, then use all the n/log(n) processors to add n/log(n) numbers divide and conquer in log(n/log(n)) time. The overall time is still O(log(n)).

Theorem for lower bound of time: A step with P processors in T time can be translated into a sequential processor in P * T time.
并行的时候，P个processor处理一次用T_1时间，和1个processor处理P次的时间。

So for best sequential time T_1, then P * T >= T_1.

So for summing, the sequential time is O(n)(in fact n-1), this is the lower bound for  * T

## Model

PRAM: Parallel Random Access Machine.

EREW: Exclusive read exclusive write.

CREW: Concurrent read exclusive write.

CRCW: Concurrent read concurrent write.

### Conflict-resolution

Common < arbitrary < priority

- arbitrary

- priority (by process index)

- common (have to write same value)

## Example 2

Find smallest number:

1. Naive: $n^2$ processors, set 1 on the larger number, return the number with 0. The time is constant.

2. Use less processors. Group by $n^{\frac{1}{2}}$, each group uses $n$ processors, altogether $n^{\frac{3}{2}}$ processors. Then merge within constant time.

3. $n$ numbers, $n^{\frac{5}{4}}$ processors: Group by $n^{\frac{1}{4}}$, the needed number of processors is just $(n^{\frac{1}{4}})^2\cdot{n}^{\frac{3}{4}}$. Then there are $n^{\frac{3}{4}}$ numbers to merge, group by $n^{\frac{3}{8}}$, the needed number of processors is $n^{\frac{9}{8}}$, less than $n^{\frac{5}{4}}$.

4. $n$ numbers, $n$ processors: Group by $\sqrt{n}$, can be merged with available $n$ processors; Subgroup by $n^{\frac{1}{4}}$, can be merged with available $\sqrt{n}$ processors, till the end. $T(n,n)=1+T(n^{\frac{1}{2}},n^{\frac{1}{2}})=i+T(n^{\frac{1}{2^i}},n^{\frac{1}{2^i}})$. When $n^{\frac{1}{2^i}}$ is constant $c$, then $i$ is $log(log(n))$.

Maximum independent set: The maximum set of vertices with no connecting edges between them.

6. When we have an algorithm using $P$ processors running in $T_P$ time, then we can simulate this algorithm with $p<P$ processors within $\frac{P\cdot{T}_P}{p}+T_p$. So this is linear for $p>n$, since we have $log(log(n))$ for $n$ and $1$ for $n^{\frac{5}{4}}$.
